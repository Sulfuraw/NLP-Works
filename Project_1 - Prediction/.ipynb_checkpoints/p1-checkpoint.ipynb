{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('wry', 6), ('year', 32), ('years', 8), ('yes', 3), ('yet', 11), ('you', 166), ('young', 12), ('your', 31), ('yourself', 5), ('zippy', 3)]\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "19.295\n"
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "\n",
    "from nltk.corpus.reader import BracketParseCorpusReader\n",
    "from nltk.lm import Vocabulary\n",
    "corpus = BracketParseCorpusReader(root=\"ressources\", fileids=[\"p1_train_Thomas.txt\"])\n",
    "text = corpus.words()\n",
    "\n",
    "vocab = Vocabulary(text, unk_cutoff=3)\n",
    "vocab_ten_last = sorted(vocab)[-10:]\n",
    "ret_array = [(0, 0)]*10\n",
    "for i in range(10):\n",
    "    word = vocab_ten_last[i]\n",
    "    ret_array[i] = (word, vocab[word])\n",
    "print(ret_array)\n",
    "\n",
    "print(\"\\n====================================================================================================\\n\")\n",
    "\n",
    "count_unk = 0\n",
    "for word in text:\n",
    "    if word not in vocab:\n",
    "        count_unk += 1\n",
    "oov = (count_unk/len(text))*100\n",
    "    \n",
    "print(\"{:.3f}\".format(oov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1:\n",
      "[('<s>', 'It'), ('It', \"'s\"), (\"'s\", 'a'), ('a', 'coming-of-age'), ('coming-of-age', 'story'), ('story', 'we'), ('we', \"'ve\"), (\"'ve\", 'all'), ('all', 'seen'), ('seen', 'bits'), ('bits', 'of'), ('of', 'in'), ('in', 'other'), ('other', 'films'), ('films', '--'), ('--', 'but'), ('but', 'it'), ('it', \"'s\"), (\"'s\", 'rarely'), ('rarely', 'been'), ('been', 'told'), ('told', 'with'), ('with', 'such'), ('such', 'affecting'), ('affecting', 'grace'), ('grace', 'and'), ('and', 'cultural'), ('cultural', 'specificity'), ('specificity', '.'), ('.', '</s>')]\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Question 2:\n",
      "{'<UNK>': 0.268, 'The': 0.1105, 'A': 0.0915}\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Question 3:\n",
      "{'<UNK>': 0.14486107364445644, 'The': 0.05988670083625573, 'A': 0.04963582411653628}\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Question 4:\n",
      "167.333\n"
     ]
    }
   ],
   "source": [
    "# Question 2\n",
    "\n",
    "from nltk.corpus.reader import BracketParseCorpusReader\n",
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "from nltk.util import bigrams\n",
    "from nltk.lm import Vocabulary\n",
    "import numpy as np\n",
    "\n",
    "# import time\n",
    "# t1 = time.time()\n",
    "\n",
    "corpus = BracketParseCorpusReader(root=\"ressources\", fileids=[\"p1_train_Thomas.txt\"])\n",
    "texts = corpus.sents()\n",
    "\n",
    "sentence_10_bi = list(bigrams(list(pad_both_ends(texts[9], n=2))))\n",
    "print(\"Question 1:\")\n",
    "print(sentence_10_bi)\n",
    "\n",
    "print(\"\\n====================================================================================================\\n\")\n",
    "print(\"Question 2:\")\n",
    "\n",
    "text = corpus.words()\n",
    "vocab = Vocabulary(text, unk_cutoff=3)\n",
    "\n",
    "mle_pers = {}\n",
    "for sentence in range(len(texts)):\n",
    "    for bi in list(bigrams(list(pad_both_ends(texts[sentence], n=2)))):\n",
    "        if bi[0] == '<s>':\n",
    "            bi = (bi[0], vocab.lookup(bi[1]))\n",
    "        elif bi[1] == '</s>':\n",
    "            bi = (vocab.lookup(bi[0]), bi[1])\n",
    "        else:\n",
    "            bi = (vocab.lookup(bi[0]), vocab.lookup(bi[1]))\n",
    "        if mle_pers.get(bi[0], -1) == -1:\n",
    "            mle_pers[bi[0]] = {}\n",
    "        count_bi = mle_pers[bi[0]].get(bi[1], 0)\n",
    "        mle_pers[bi[0]][bi[1]] = count_bi+1\n",
    "\n",
    "count_nexts = {}\n",
    "key_nexts = {}\n",
    "for first_word in mle_pers.keys():    \n",
    "    count_next = 0\n",
    "    for i in mle_pers[first_word]:\n",
    "        count_next += mle_pers[first_word][i]\n",
    "    count_nexts[first_word] = count_next\n",
    "    for second_word in mle_pers[first_word].keys():\n",
    "        previous = mle_pers[first_word][second_word]\n",
    "        mle_pers[first_word][second_word] = previous/count_nexts[first_word]\n",
    "        \n",
    "    key_next = list(mle_pers[first_word].keys())\n",
    "    key_next = sorted(key_next, key= mle_pers[first_word].__getitem__)\n",
    "    key_nexts[first_word] = key_next   \n",
    "\n",
    "ret_dict_mle = {}\n",
    "ret_dict_mle[key_nexts[\"<s>\"][-1]] = mle_pers[\"<s>\"][key_nexts[\"<s>\"][-1]]  #\"{:.4f}\".format()\n",
    "ret_dict_mle[key_nexts[\"<s>\"][-2]] = mle_pers[\"<s>\"][key_nexts[\"<s>\"][-2]]\n",
    "ret_dict_mle[key_nexts[\"<s>\"][-3]] = mle_pers[\"<s>\"][key_nexts[\"<s>\"][-3]]\n",
    "print(ret_dict_mle)\n",
    "\n",
    "print(\"\\n====================================================================================================\\n\")\n",
    "print(\"Question 3:\")\n",
    "\n",
    "mle_pers = {}\n",
    "        \n",
    "for sentence in range(len(texts)):\n",
    "    for bi in list(bigrams(list(pad_both_ends(texts[sentence], n=2)))):\n",
    "        if bi[0] == '<s>':\n",
    "            bi = (bi[0], vocab.lookup(bi[1]))\n",
    "        elif bi[1] == '</s>':\n",
    "            bi = (vocab.lookup(bi[0]), bi[1])\n",
    "        else:\n",
    "            bi = (vocab.lookup(bi[0]), vocab.lookup(bi[1]))\n",
    "        if mle_pers.get(bi[0], -1) == -1:\n",
    "            mle_pers[bi[0]] = {}\n",
    "        count_bi = mle_pers[bi[0]].get(bi[1], 1)\n",
    "        mle_pers[bi[0]][bi[1]] = count_bi+1\n",
    "\n",
    "key_nexts = {}\n",
    "len_vocab = len(vocab)\n",
    "for first_word in mle_pers.keys():\n",
    "    for second_word in mle_pers[first_word].keys():\n",
    "        previous = mle_pers[first_word][second_word]\n",
    "        mle_pers[first_word][second_word] = previous/(count_nexts[first_word] + len_vocab + 3)\n",
    "    key_next = list(mle_pers[first_word].keys())\n",
    "    key_next = sorted(key_next, key= mle_pers[first_word].__getitem__)\n",
    "    key_nexts[first_word] = key_next\n",
    "\n",
    "ret_dict_mle = {}\n",
    "ret_dict_mle[key_nexts[\"<s>\"][-1]] = mle_pers[\"<s>\"][key_nexts[\"<s>\"][-1]]  #\"{:.4f}\".format()\n",
    "ret_dict_mle[key_nexts[\"<s>\"][-2]] = mle_pers[\"<s>\"][key_nexts[\"<s>\"][-2]]\n",
    "ret_dict_mle[key_nexts[\"<s>\"][-3]] = mle_pers[\"<s>\"][key_nexts[\"<s>\"][-3]]\n",
    "print(ret_dict_mle)\n",
    "\n",
    "print(\"\\n====================================================================================================\\n\")\n",
    "print(\"Question 4:\")\n",
    "\n",
    "test_set = BracketParseCorpusReader(root=\"ressources\", fileids=[\"p1_test_Thomas.txt\"]).sents()\n",
    "\n",
    "mult_score = 0\n",
    "M = 0\n",
    "for sentence in range(len(test_set)):\n",
    "    for bi in list(bigrams(list(pad_both_ends(test_set[sentence], n=2)))):\n",
    "        if bi[0] == '<s>':\n",
    "            bi = (bi[0], vocab.lookup(bi[1]))\n",
    "        elif bi[1] == '</s>':\n",
    "            bi = (vocab.lookup(bi[0]), bi[1])\n",
    "        else:\n",
    "            bi = (vocab.lookup(bi[0]), vocab.lookup(bi[1]))\n",
    "        mult_score += np.log2(mle_pers[bi[0]].get(bi[1], 1/(count_nexts[bi[0]] + len_vocab + 3)))\n",
    "        M += 1\n",
    "        \n",
    "LL = mult_score/M\n",
    "PP = 2**(-LL)\n",
    "print(\"{:.3f}\".format(PP))\n",
    "\n",
    "# t2 = time.time()\n",
    "# print(\"temps pris : \"+ str((t2-t1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.0\n"
     ]
    }
   ],
   "source": [
    "# Question 3\n",
    "\n",
    "from nltk.corpus.reader import BracketParseCorpusReader\n",
    "from nltk.lm import Vocabulary\n",
    "import numpy as np\n",
    "\n",
    "corpus = BracketParseCorpusReader(root=\"ressources\", fileids=[\"p1_train_Thomas.txt\"])\n",
    "parsed_texts = corpus.parsed_sents()\n",
    "vocab = Vocabulary(corpus.words(), unk_cutoff=3)\n",
    "\n",
    "N_neg = 0\n",
    "N_pos = 0\n",
    "N_doc = len(parsed_texts)\n",
    "bag_neg = {}\n",
    "bag_pos = {}\n",
    "for sentence in range(N_doc):\n",
    "    sequence = parsed_texts[sentence]\n",
    "    if int(sequence.label()) < 2:\n",
    "        N_neg += 1\n",
    "        for word in sequence.leaves():\n",
    "            bag_neg[word] = bag_neg.get(word, 0) + 1\n",
    "    else:\n",
    "        N_pos += 1\n",
    "        for word in sequence.leaves():\n",
    "            bag_pos[word] = bag_pos.get(word, 0) + 1\n",
    "\n",
    "count_neg = 0\n",
    "for word in bag_neg.keys():\n",
    "    count_neg += bag_neg[word]\n",
    "count_pos = 0\n",
    "for word in bag_pos.keys():\n",
    "    count_pos += bag_pos[word]\n",
    "    \n",
    "test = BracketParseCorpusReader(root=\"ressources\", fileids=[\"p1_test_Thomas.txt\"])\n",
    "test_set = test.sents()\n",
    "\n",
    "test_pred = [0]*len(test_set)\n",
    "vocab_len = len(vocab) + 2\n",
    "for sentence in range(len(test_set)):\n",
    "    neg_score = 0\n",
    "    pos_score = 0\n",
    "    for word in test_set[sentence]:\n",
    "        if word in vocab:\n",
    "            neg_score += np.log( (bag_neg.get(word, 0) + 1) / (count_neg + vocab_len) )\n",
    "            pos_score += np.log( (bag_pos.get(word, 0) + 1) / (count_pos + vocab_len) )\n",
    "    \n",
    "    neg_score += np.log((N_neg/N_doc))    # Ajout du prior avec les logs\n",
    "    pos_score += np.log((N_pos/N_doc))\n",
    "    if neg_score > pos_score:\n",
    "        test_pred[sentence] = 0\n",
    "    else:\n",
    "        test_pred[sentence] = 1\n",
    "\n",
    "test_verif = test.parsed_sents()\n",
    "ratio = 0\n",
    "for sentence in range(len(test_set)):\n",
    "    y = int(test_verif[sentence].label())\n",
    "    if (test_pred[sentence] == (y>=2)):\n",
    "        ratio += 1\n",
    "print((ratio/len(test_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.5\n"
     ]
    }
   ],
   "source": [
    "# Question 4\n",
    "# 1) Binary Naive Bias\n",
    "\n",
    "from nltk.corpus.reader import BracketParseCorpusReader\n",
    "from nltk.lm import Vocabulary\n",
    "import numpy as np\n",
    "\n",
    "corpus = BracketParseCorpusReader(root=\"ressources\", fileids=[\"p1_train_Thomas.txt\"])\n",
    "parsed_texts = corpus.parsed_sents()\n",
    "vocab = Vocabulary(corpus.words(), unk_cutoff=3)\n",
    "\n",
    "N_neg = 0\n",
    "N_pos = 0\n",
    "N_doc = len(parsed_texts)\n",
    "bag_neg = {}\n",
    "bag_pos = {}\n",
    "for sentence in range(N_doc):\n",
    "    sequence = parsed_texts[sentence]\n",
    "    words_seen = []\n",
    "    if int(sequence.label()) < 2:\n",
    "        N_neg += 1\n",
    "        for word in sequence.leaves():\n",
    "            if word not in words_seen:\n",
    "                bag_neg[word] = bag_neg.get(word, 0) + 1\n",
    "                words_seen.append(word)\n",
    "    else:\n",
    "        N_pos += 1\n",
    "        for word in sequence.leaves():\n",
    "            if word not in words_seen:\n",
    "                bag_pos[word] = bag_pos.get(word, 0) + 1\n",
    "                words_seen.append(word)\n",
    "\n",
    "count_neg = 0\n",
    "for word in bag_neg.keys():\n",
    "    count_neg += bag_neg[word]\n",
    "count_pos = 0\n",
    "for word in bag_pos.keys():\n",
    "    count_pos += bag_pos[word]\n",
    "    \n",
    "test = BracketParseCorpusReader(root=\"ressources\", fileids=[\"p1_test_Thomas.txt\"])\n",
    "test_set = test.sents()\n",
    "\n",
    "test_pred = [0]*len(test_set)\n",
    "vocab_len = len(vocab) + 2\n",
    "for sentence in range(len(test_set)):\n",
    "    neg_score = 0\n",
    "    pos_score = 0\n",
    "    words_seen = []\n",
    "    for word in test_set[sentence]:\n",
    "        if word in vocab and word not in words_seen:\n",
    "            neg_score += np.log( (bag_neg.get(word, 0) + 1) / (count_neg + vocab_len) )\n",
    "            pos_score += np.log( (bag_pos.get(word, 0) + 1) / (count_pos + vocab_len) )\n",
    "            words_seen.append(word)\n",
    "    \n",
    "    neg_score += np.log((N_neg/N_doc))\n",
    "    pos_score += np.log((N_pos/N_doc))\n",
    "    if neg_score > pos_score:\n",
    "        test_pred[sentence] = 0\n",
    "    else:\n",
    "        test_pred[sentence] = 1\n",
    "\n",
    "test_verif = test.parsed_sents()\n",
    "ratio = 0\n",
    "for sentence in range(len(test_set)):\n",
    "    y = int(test_verif[sentence].label())\n",
    "    if (test_pred[sentence] == (y>=2)):\n",
    "        ratio += 1\n",
    "print((ratio/len(test_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.5\n"
     ]
    }
   ],
   "source": [
    "# Question 4\n",
    "# 2) negative\n",
    "\n",
    "from nltk.corpus.reader import BracketParseCorpusReader\n",
    "from nltk.lm import Vocabulary\n",
    "import numpy as np\n",
    "\n",
    "corpus = BracketParseCorpusReader(root=\"ressources\", fileids=[\"p1_train_Thomas.txt\"])\n",
    "parsed_texts = corpus.parsed_sents()\n",
    "vocab = Vocabulary(corpus.words(), unk_cutoff=3)\n",
    "negate = [\"n't\", \"not\", \"no\", \"never\"]\n",
    "punct = ['.', ',', ':', '?', '!']\n",
    "\n",
    "N_neg = 0\n",
    "N_pos = 0\n",
    "N_doc = len(parsed_texts)\n",
    "bag_neg = {}\n",
    "bag_pos = {}\n",
    "neg_words_seen = set()\n",
    "for sentence in range(N_doc):\n",
    "    sequence = parsed_texts[sentence]\n",
    "    in_neg = False\n",
    "    if int(sequence.label()) < 2:\n",
    "        N_neg += 1\n",
    "        for word in sequence.leaves():\n",
    "            if word in punct: in_neg = False\n",
    "            if in_neg: \n",
    "                if word in vocab:\n",
    "                    neg_words_seen.add(word+\"_NOT\")\n",
    "                word += \"_NOT\"\n",
    "            bag_neg[word] = bag_neg.get(word, 0) + 1\n",
    "            if word in negate: in_neg = True\n",
    "    else:\n",
    "        N_pos += 1\n",
    "        for word in sequence.leaves():\n",
    "            if word in punct: in_neg = False\n",
    "            if in_neg: \n",
    "                if word in vocab:\n",
    "                    neg_words_seen.add(word+\"_NOT\")\n",
    "                word += \"_NOT\"\n",
    "            bag_pos[word] = bag_pos.get(word, 0) + 1\n",
    "            if word in negate: in_neg = True\n",
    "\n",
    "\n",
    "count_neg = 0\n",
    "for word in bag_neg.keys():\n",
    "    count_neg += bag_neg[word]\n",
    "count_pos = 0\n",
    "for word in bag_pos.keys():\n",
    "    count_pos += bag_pos[word]\n",
    "    \n",
    "test = BracketParseCorpusReader(root=\"ressources\", fileids=[\"p1_test_Thomas.txt\"])\n",
    "test_set = test.sents()\n",
    "\n",
    "\n",
    "test_pred = [0]*len(test_set)\n",
    "vocab_len = len(vocab) + 2\n",
    "for sentence in range(len(test_set)):\n",
    "    neg_score = 0\n",
    "    pos_score = 0\n",
    "    in_neg = False\n",
    "    for word in test_set[sentence]:\n",
    "        if word in punct: in_neg = False\n",
    "        if in_neg:\n",
    "            word += \"_NOT\"\n",
    "        if word in vocab or word in neg_words_seen:\n",
    "            neg_score += np.log( (bag_neg.get(word, 0) + 1) / (count_neg + vocab_len) )\n",
    "            pos_score += np.log( (bag_pos.get(word, 0) + 1) / (count_pos + vocab_len) )\n",
    "        if word in negate: in_neg = True\n",
    "    \n",
    "    neg_score += np.log((N_neg/N_doc))\n",
    "    pos_score += np.log((N_pos/N_doc))\n",
    "    if neg_score > pos_score:\n",
    "        test_pred[sentence] = 0\n",
    "    else:\n",
    "        test_pred[sentence] = 1\n",
    "\n",
    "test_verif = test.parsed_sents()\n",
    "ratio = 0\n",
    "for sentence in range(len(test_set)):\n",
    "    y = int(test_verif[sentence].label())\n",
    "    if (test_pred[sentence] == (y>=2)):\n",
    "        ratio += 1\n",
    "print((ratio/len(test_set))*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
