{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction: \n",
    "This project is divided in two. The first part is about completion (prediction) of words via some context or none. And the second part is dedicated to categorization of sentences for sentiment analysis.\n",
    "\n",
    "It involves the use of:\n",
    "\n",
    "- Maximum likelihood estimation (MLE)\n",
    "- MLE with laplace smoothing\n",
    "- Test set perplexity\n",
    "* Bag of words\n",
    "* Binary Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader import BracketParseCorpusReader\n",
    "from nltk.lm import Vocabulary\n",
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "from nltk.util import bigrams\n",
    "import numpy as np\n",
    "\n",
    "corpus = BracketParseCorpusReader(root=\"corpora\", fileids=[\"p1_train.txt\"])\n",
    "words = corpus.words()\n",
    "sentences = corpus.sents()\n",
    "parsed_texts = corpus.parsed_sents()\n",
    "test = BracketParseCorpusReader(root=\"corpora\", fileids=[\"p1_test.txt\"])\n",
    "test_set = test.sents()\n",
    "vocab = Vocabulary(words, unk_cutoff=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Little checks over the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our vocabulary, we have put all the words of the corpus that appear at least 3 times. Other present words are replace by the token \\<UNK> as of every other words not present in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 last words of the vocabulary with their number of appearence in the corpus:\n",
      "  [('wry', 6), ('year', 32), ('years', 8), ('yes', 3), ('yet', 11), ('you', 166), ('young', 12), ('your', 31), ('yourself', 5), ('zippy', 3)]\n"
     ]
    }
   ],
   "source": [
    "word_num = []\n",
    "for word in sorted(vocab)[-10:]:\n",
    "    word_num.append((word, vocab[word]))\n",
    "print(f\"The 10 last words of the vocabulary with their number of appearence in the corpus:\\n  {word_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unkown words: 7352\n",
      "Out of vocabulary (OOV) rate: 19.295%\n"
     ]
    }
   ],
   "source": [
    "count_unk = 0\n",
    "for word in words:\n",
    "    if word not in vocab:\n",
    "        count_unk += 1\n",
    "oov = (count_unk/len(words))*100\n",
    "\n",
    "print(f\"The number of unkown words: {count_unk}\")\n",
    "print(f\"Out of vocabulary (OOV) rate: {round(oov, 3)}%\".format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the bigrams of the 10th sentence:\n",
      "  [('<s>', 'It'), ('It', \"'s\"), (\"'s\", 'a'), ('a', 'coming-of-age'), ('coming-of-age', 'story'), ('story', 'we'), ('we', \"'ve\"), (\"'ve\", 'all'), ('all', 'seen'), ('seen', 'bits'), ('bits', 'of'), ('of', 'in'), ('in', 'other'), ('other', 'films'), ('films', '--'), ('--', 'but'), ('but', 'it'), ('it', \"'s\"), (\"'s\", 'rarely'), ('rarely', 'been'), ('been', 'told'), ('told', 'with'), ('with', 'such'), ('such', 'affecting'), ('affecting', 'grace'), ('grace', 'and'), ('and', 'cultural'), ('cultural', 'specificity'), ('specificity', '.'), ('.', '</s>')]\n"
     ]
    }
   ],
   "source": [
    "sentence_10_bi = list(bigrams(list(pad_both_ends(sentences[9], n=2))))\n",
    "print(f\"All the bigrams of the 10th sentence:\\n  {sentence_10_bi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text completion part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum-likelihood estimation (MLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probabilty of having a word (w) if we know the history (h) (context).\n",
    "\n",
    "Since we don't know the probability, we estimate it by counting over the corpus.\n",
    "\n",
    "The counting function is noted $C(*)$\n",
    "\n",
    "$\\^P(w|h) = \\frac{C(h,w)}{C(h)}$\n",
    "\n",
    "(if the $C(h) <= 0$ then $\\^P(w|h) = 0$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is needed to compute both mle and mle_laplace\n",
    "\n",
    "# bi_count == C(h,w)\n",
    "bi_count = {}\n",
    "# mle will be == P(w|h) after computation, same for mle_laplace with the smoothing\n",
    "# Not computed here, only initialised\n",
    "mle = {}\n",
    "mle_laplace = {}\n",
    "for sentence in range(len(sentences)):\n",
    "    for bi in list(bigrams(list(pad_both_ends(sentences[sentence], n=2)))):\n",
    "        if bi[0] == '<s>':\n",
    "            bi = (bi[0], vocab.lookup(bi[1]))\n",
    "        elif bi[1] == '</s>':\n",
    "            bi = (vocab.lookup(bi[0]), bi[1])\n",
    "        else:\n",
    "            bi = (vocab.lookup(bi[0]), vocab.lookup(bi[1]))\n",
    "        if bi_count.get(bi[0], -1) == -1:\n",
    "            bi_count[bi[0]] = {}\n",
    "            mle[bi[0]] = {}\n",
    "            mle_laplace[bi[0]] = {}\n",
    "        count_bi = bi_count[bi[0]].get(bi[1], 0)\n",
    "        bi_count[bi[0]][bi[1]] = count_bi+1\n",
    "\n",
    "# h_count == C(h)\n",
    "h_count = {}\n",
    "for first_word in bi_count.keys():    \n",
    "    count_next = 0\n",
    "    for i in bi_count[first_word]:\n",
    "        count_next += bi_count[first_word][i]\n",
    "    h_count[first_word] = count_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mle\n",
    "\n",
    "best_nexts_key_mle = {}\n",
    "for first_word in bi_count.keys():    \n",
    "    for second_word in bi_count[first_word].keys():\n",
    "        previous = bi_count[first_word][second_word]\n",
    "        mle[first_word][second_word] = previous/h_count[first_word]\n",
    "        \n",
    "    key_next = list(mle[first_word].keys())\n",
    "    key_next = sorted(key_next, key= mle[first_word].__getitem__)\n",
    "    best_nexts_key_mle[first_word] = key_next   \n",
    "\n",
    "def complete_next_word_mle(target):\n",
    "    ret = {}\n",
    "    nexts = best_nexts_key_mle[target]\n",
    "    for i in range(5):\n",
    "        ret[nexts[-i-1]] = round(mle[target][nexts[-i-1]], 4)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most probable completion after a target word (<s> is the start of a sentence):\n",
      "\n",
      "After the target <s>:\n",
      "- <UNK>: 0.268\n",
      "- The: 0.1105\n",
      "- A: 0.0915\n",
      "- It: 0.075\n",
      "- This: 0.0345\n",
      "After the target love:\n",
      "- story: 0.1923\n",
      "- <UNK>: 0.1538\n",
      "- ,: 0.1154\n",
      "- and: 0.0769\n",
      "- with: 0.0769\n"
     ]
    }
   ],
   "source": [
    "# Run example\n",
    "\n",
    "print(\"The 5 most probable completion after a target word (<s> is the start of a sentence):\\n\")\n",
    "for target in [\"<s>\", \"love\"]:\n",
    "    print(f\"After the target {target}:\")\n",
    "    for word, proba in complete_next_word_mle(target).items():\n",
    "        print(f\"- {word}: {proba}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLE with Laplace smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approximation is smoothed via the following formula:\n",
    "\n",
    "$\\^P(w|h) = \\frac{C(h,w) + 1}{C(h) + |V|}$\n",
    "\n",
    "$|V|$ being the size of the vocabulary. More precisely in the code, it's the size of the vocabulary plus 3 tokens: \n",
    "- \\<s> is the start of sentence token\n",
    "- \\</s> is the end of sentence token\n",
    "- \\<UNK> is the token for every word outside of the vocabulary (less than 3 occurence in the corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mle_laplace (smoothed)\n",
    "\n",
    "best_nexts_key_mle_laplace = {}\n",
    "V = len(vocab) + 3\n",
    "for first_word in bi_count.keys():\n",
    "    for second_word in bi_count[first_word].keys():\n",
    "        previous = bi_count[first_word][second_word]\n",
    "        mle_laplace[first_word][second_word] = (previous + 1) / (h_count[first_word] + V)\n",
    "\n",
    "    key_next = list(mle_laplace[first_word].keys())\n",
    "    key_next = sorted(key_next, key= mle_laplace[first_word].__getitem__)\n",
    "    best_nexts_key_mle_laplace[first_word] = key_next\n",
    "\n",
    "def complete_next_word_mle_laplace(target):\n",
    "    ret = {}\n",
    "    nexts = best_nexts_key_mle_laplace[target]\n",
    "    for i in range(5):\n",
    "        ret[nexts[-i-1]] = round(mle_laplace[target][nexts[-i-1]], 4)\n",
    "    return ret\n",
    "\n",
    "# {'<UNK>': 0.14486107364445644, 'The': 0.05988670083625573, 'A': 0.04963582411653628}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most probable completion after a target word (<s> is the start of a sentence) via the laplace smooth:\n",
      "\n",
      "After the target <s>:\n",
      "- <UNK>: 0.1449\n",
      "- The: 0.0599\n",
      "- A: 0.0496\n",
      "- It: 0.0407\n",
      "- This: 0.0189\n",
      "After the target love:\n",
      "- story: 0.0035\n",
      "- <UNK>: 0.0029\n",
      "- ,: 0.0023\n",
      "- and: 0.0017\n",
      "- with: 0.0017\n"
     ]
    }
   ],
   "source": [
    "# Run example\n",
    "\n",
    "print(\"The 5 most probable completion after a target word (<s> is the start of a sentence) via the laplace smooth:\\n\")\n",
    "for target in [\"<s>\", \"love\"]:\n",
    "    print(f\"After the target {target}:\")\n",
    "    for word, proba in complete_next_word_mle_laplace(target).items():\n",
    "        print(f\"- {word}: {proba}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test set perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lower it is, the better. Because better model are more predictive and less uniformly random.\n",
    "\n",
    "It can be interpreted as the number of words among which one predicts, if one would predict uniformly at random.\n",
    "\n",
    "$|V| = 10000$ and $PP = 100$ means that the uncertainty is the same as if one would predict only among 100 possibilities with an equal probability of $\\frac{1}{100}$ for each word.\n",
    "\n",
    "The model actually predicts among 10'000 possibilities but with unequal probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set perplexity PP: 167.333\n"
     ]
    }
   ],
   "source": [
    "# Care we use the test_set corpus here\n",
    "# So some words may not be present in the training but do here\n",
    "# Compute using 1/(h_count[bi[0]] + V)))\n",
    "\n",
    "mult_score = 0\n",
    "M = 0\n",
    "for sentence in range(len(test_set)):\n",
    "    for bi in list(bigrams(list(pad_both_ends(test_set[sentence], n=2)))):\n",
    "        if bi[0] == '<s>':\n",
    "            bi = (bi[0], vocab.lookup(bi[1]))\n",
    "        elif bi[1] == '</s>':\n",
    "            bi = (vocab.lookup(bi[0]), bi[1])\n",
    "        else:\n",
    "            bi = (vocab.lookup(bi[0]), vocab.lookup(bi[1]))\n",
    "        mult_score += np.log2(mle_laplace[bi[0]].get(bi[1], \n",
    "                                                     1/(h_count[bi[0]] + V)))\n",
    "        M += 1\n",
    "        \n",
    "LL = mult_score/M\n",
    "PP = 2**(-LL)\n",
    "print(\"Test set perplexity PP: {:.3f}\".format(PP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Categorization\n",
    "\n",
    "The task of assigning a label or a category to an entire text or document. Here it is aim at sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Words\n",
    "\n",
    "Representation of a text document in an unordered set of words with their frequency in the document.\n",
    "\n",
    "There are used for counting efficiently their appearence in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Naive Bayes\n",
    "\n",
    "The formula for the Naive Bayes decision rule:\n",
    "\n",
    "$C_{NB} = argmax_{c \\in C} [log P(c) + \\sum_i log P(w_i | c)]$\n",
    "\n",
    "With\n",
    "\n",
    "$\\^P(c) = \\frac{N_c}{N_{doc}}$\n",
    "\n",
    "$\\^P(w_i | c) = \\frac{n_{w_i, c} + 1}{\\sum_{w \\in V} n_{w, c} + |V|}$\n",
    "\n",
    "With:\n",
    "- $N_c$ the number of doc labeled of class $c$ in training set\n",
    "- $N_{doc}$ the number of doc in total in training set\n",
    "- $n_{w_i, c}$ the number of occurences of word $w_i$ in all documents labeled $c$\n",
    "- V the vocabulary size (no \\<UNK> here because they are ignored from the bag of words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation of the variable for the computation on the train corpus\n",
    "N_neg = 0 # Nc1\n",
    "N_pos = 0 # Nc2\n",
    "N_doc = len(parsed_texts) #Ndoc\n",
    "bag_neg = {} # nwi,c1\n",
    "bag_pos = {} # nwi,c2\n",
    "count_neg = 0 # Sum (nw,c1)\n",
    "count_pos = 0 # Sum (nw,c2)\n",
    "for sentence in range(N_doc):\n",
    "    sequence = parsed_texts[sentence]\n",
    "    if int(sequence.label()) < 2:\n",
    "        N_neg += 1\n",
    "        for word in sequence.leaves():\n",
    "            count_neg += 1\n",
    "            bag_neg[word] = bag_neg.get(word, 0) + 1\n",
    "    else:\n",
    "        N_pos += 1\n",
    "        for word in sequence.leaves():\n",
    "            count_pos += 1\n",
    "            bag_pos[word] = bag_pos.get(word, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.0\n"
     ]
    }
   ],
   "source": [
    "# Verification / testing on the test corpus\n",
    "test_pred = [0]*len(test_set)\n",
    "vocab_len = len(vocab) + 2\n",
    "for sentence in range(len(test_set)):\n",
    "    neg_score = 0\n",
    "    pos_score = 0\n",
    "    for word in test_set[sentence]:\n",
    "        if word in vocab:\n",
    "            # Sum log P(wi|c1)\n",
    "            neg_score += np.log( (bag_neg.get(word, 0) + 1) / (count_neg + vocab_len) )\n",
    "            pos_score += np.log( (bag_pos.get(word, 0) + 1) / (count_pos + vocab_len) )\n",
    "    \n",
    "    neg_score += np.log((N_neg/N_doc))    # Adding the prior log(P(c1))\n",
    "    pos_score += np.log((N_pos/N_doc))\n",
    "    # Pick the category that has the highest value\n",
    "    if neg_score > pos_score:\n",
    "        test_pred[sentence] = 0\n",
    "    else:\n",
    "        test_pred[sentence] = 1\n",
    "\n",
    "test_verif = test.parsed_sents()\n",
    "ratio = 0\n",
    "for sentence in range(len(test_set)):\n",
    "    y = int(test_verif[sentence].label())\n",
    "    if (test_pred[sentence] == (y>=2)):\n",
    "        ratio += 1\n",
    "print((ratio/len(test_set))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Naive Bayes with small modification\n",
    "\n",
    "Next we will introduces a list (words_seen) to keep track of words already counted to avoid double counting within the same sentence. This modification is as an attempt to capture the \"bag-of-words\" characteristics more accurately, especially if the same word occurs multiple times within the same sentence. Trying to be less biased by the corpus where some words may be overly used in the same sentence at some point.\n",
    "\n",
    "All the comments from the code above is applicable below since it is mostly the same code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_neg = 0\n",
    "N_pos = 0\n",
    "N_doc = len(parsed_texts)\n",
    "bag_neg = {}\n",
    "bag_pos = {}\n",
    "count_neg = 0\n",
    "count_pos = 0\n",
    "for sentence in range(N_doc):\n",
    "    sequence = parsed_texts[sentence]\n",
    "    words_seen = []\n",
    "    if int(sequence.label()) < 2:\n",
    "        N_neg += 1\n",
    "        for word in sequence.leaves():\n",
    "            if word not in words_seen:\n",
    "                count_neg += 1\n",
    "                bag_neg[word] = bag_neg.get(word, 0) + 1\n",
    "                words_seen.append(word)\n",
    "    else:\n",
    "        N_pos += 1\n",
    "        for word in sequence.leaves():\n",
    "            if word not in words_seen:\n",
    "                count_pos += 1\n",
    "                bag_pos[word] = bag_pos.get(word, 0) + 1\n",
    "                words_seen.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.5\n"
     ]
    }
   ],
   "source": [
    "test_pred = [0]*len(test_set)\n",
    "vocab_len = len(vocab) + 2\n",
    "for sentence in range(len(test_set)):\n",
    "    neg_score = 0\n",
    "    pos_score = 0\n",
    "    words_seen = []\n",
    "    for word in test_set[sentence]:\n",
    "        if word in vocab and word not in words_seen:\n",
    "            neg_score += np.log( (bag_neg.get(word, 0) + 1) / (count_neg + vocab_len) )\n",
    "            pos_score += np.log( (bag_pos.get(word, 0) + 1) / (count_pos + vocab_len) )\n",
    "            words_seen.append(word)\n",
    "    \n",
    "    neg_score += np.log((N_neg/N_doc))\n",
    "    pos_score += np.log((N_pos/N_doc))\n",
    "    if neg_score > pos_score:\n",
    "        test_pred[sentence] = 0\n",
    "    else:\n",
    "        test_pred[sentence] = 1\n",
    "\n",
    "test_verif = test.parsed_sents()\n",
    "ratio = 0\n",
    "for sentence in range(len(test_set)):\n",
    "    y = int(test_verif[sentence].label())\n",
    "    if (test_pred[sentence] == (y>=2)):\n",
    "        ratio += 1\n",
    "print((ratio/len(test_set))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Naive Bayes with negation modification\n",
    "\n",
    "Next we do an additionnal modification of the code to even more categorize the words within a negative sentence from a positive one. Introducing the modification of words using the following rule:\n",
    "\n",
    "If we encounter a negative word (i.e \"n't\", \"not\", \"no\", \"never\"), then the next words till a punctuation are transformed: \"word\" --> \"word_NOT\"\n",
    "\n",
    "The goal here is to distinguish the use a word that could be negate. For example, take the following sentences: \"You're beautiful\" and \"You're not beautiful\", as we can see beautifull (a positive words) can be present in negative sentence as well as positive ones, the meaning is inversed because of the not.\n",
    "\n",
    "These transformation are then used in the training with the bags and the count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "negate = [\"n't\", \"not\", \"no\", \"never\"]\n",
    "punct = ['.', ',', ':', '?', '!']\n",
    "\n",
    "N_neg = 0\n",
    "N_pos = 0\n",
    "N_doc = len(parsed_texts)\n",
    "bag_neg = {}\n",
    "bag_pos = {}\n",
    "count_neg = 0\n",
    "count_pos = 0\n",
    "neg_words_seen = set()\n",
    "for sentence in range(N_doc):\n",
    "    sequence = parsed_texts[sentence]\n",
    "    in_neg = False\n",
    "    if int(sequence.label()) < 2:\n",
    "        N_neg += 1\n",
    "        for word in sequence.leaves():\n",
    "            if word in punct: in_neg = False\n",
    "            if in_neg: \n",
    "                if word in vocab:\n",
    "                    neg_words_seen.add(word+\"_NOT\")\n",
    "                word += \"_NOT\"\n",
    "            count_neg += 1\n",
    "            bag_neg[word] = bag_neg.get(word, 0) + 1\n",
    "            if word in negate: in_neg = True\n",
    "    else:\n",
    "        N_pos += 1\n",
    "        for word in sequence.leaves():\n",
    "            if word in punct: in_neg = False\n",
    "            if in_neg: \n",
    "                if word in vocab:\n",
    "                    neg_words_seen.add(word+\"_NOT\")\n",
    "                word += \"_NOT\"\n",
    "            count_pos += 1\n",
    "            bag_pos[word] = bag_pos.get(word, 0) + 1\n",
    "            if word in negate: in_neg = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.5\n"
     ]
    }
   ],
   "source": [
    "test_pred = [0]*len(test_set)\n",
    "vocab_len = len(vocab) + 2\n",
    "for sentence in range(len(test_set)):\n",
    "    neg_score = 0\n",
    "    pos_score = 0\n",
    "    in_neg = False\n",
    "    for word in test_set[sentence]:\n",
    "        if word in punct: in_neg = False\n",
    "        if in_neg:\n",
    "            word += \"_NOT\"\n",
    "        if word in vocab or word in neg_words_seen:\n",
    "            neg_score += np.log( (bag_neg.get(word, 0) + 1) / (count_neg + vocab_len) )\n",
    "            pos_score += np.log( (bag_pos.get(word, 0) + 1) / (count_pos + vocab_len) )\n",
    "        if word in negate: in_neg = True\n",
    "    \n",
    "    neg_score += np.log((N_neg/N_doc))\n",
    "    pos_score += np.log((N_pos/N_doc))\n",
    "    if neg_score > pos_score:\n",
    "        test_pred[sentence] = 0\n",
    "    else:\n",
    "        test_pred[sentence] = 1\n",
    "\n",
    "test_verif = test.parsed_sents()\n",
    "ratio = 0\n",
    "for sentence in range(len(test_set)):\n",
    "    y = int(test_verif[sentence].label())\n",
    "    if (test_pred[sentence] == (y>=2)):\n",
    "        ratio += 1\n",
    "print((ratio/len(test_set))*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
